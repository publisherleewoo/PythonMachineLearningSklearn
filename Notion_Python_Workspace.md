# ğŸ Python Workspace - Jupyter ë…¸íŠ¸ë¶ ì™„ì „ ì •ë¦¬

ğŸ“… **ì •ë¦¬ ë‚ ì§œ**: 2025ë…„ 09ì›” 21ì¼ 21ì‹œ 30ë¶„
ğŸ“ **ì†ŒìŠ¤ ê²½ë¡œ**: `C:\pythonworkspace`
ğŸ“Š **ì´ ë…¸íŠ¸ë¶ ìˆ˜**: 6ê°œ

---

## ğŸ“‘ ëª©ì°¨

1. [01. Linear Regression.ipynb](#01.-linear-regression)
2. [02. Multiple Linear Regression.ipynb](#02.-multiple-linear-regression)
3. [03. Polynomial Regression.ipynb](#03.-polynomial-regression)
4. [04. Logistic Regression.ipynb](#04.-logistic-regression)
5. [05. K-Means.ipynb](#05.-k-means)
6. [06. Quiz.ipynb](#06.-quiz)

---

## ğŸ““ 01. Linear Regression.ipynb

> **íŒŒì¼ ê²½ë¡œ**: `C:\pythonworkspace\01. Linear Regression.ipynb`
> **ì´ ì…€ ê°œìˆ˜**: 43ê°œ

### ğŸ“ ì…€ 1 - ë§ˆí¬ë‹¤ìš´

# 1. Linear Regression
### ê³µë¶€ ì‹œê°„ì— ë”°ë¥¸ ì‹œí—˜ ì ìˆ˜

---

### ğŸ’» ì…€ 2 - ì½”ë“œ

```python
import matplotlib.pyplot as plt
import pandas as pd
```

---

### ğŸ’» ì…€ 3 - ì½”ë“œ

```python
dataset = pd.read_csv('LinearRegressionData.csv')
```

---

### ğŸ’» ì…€ 4 - ì½”ë“œ

```python
dataset.head()
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
hour  score
0   0.5     10
1   1.2      8
2   1.8     14
3   2.4     26
4   2.6     22
```

---

### ğŸ’» ì…€ 5 - ì½”ë“œ

```python
X = dataset.iloc[:, :-1].values # ì²˜ìŒë¶€í„° ë§ˆì§€ë§‰ ì»¬ëŸ¼ ì§ì „ê¹Œì§€ì˜ ë°ì´í„° (ë…ë¦½ ë³€ìˆ˜ - ì›ì¸)
y = dataset.iloc[:, -1].values # ë§ˆì§€ë§‰ ì»¬ëŸ¼ ë°ì´í„° (ì¢…ì† ë³€ìˆ˜ - ê²°ê³¼)
```

---

### ğŸ’» ì…€ 6 - ì½”ë“œ

```python
X, y
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
(array([[ 0.5],
        [ 1.2],
        [ 1.8],
        [ 2.4],
        [ 2.6],
        [ 3.2],
        [ 3.9],
        [ 4.4],
        [ 4.5],
        [ 5. ],
        [ 5.3],
        [ 5.8],
        [ 6. ],
        [ 6.1],
        [ 6.2],
        [ 6.9],
        [ 7.2],
        [ 8.4],
        [ 8.6],
        [10. ]]),
 array([ 10,   8,  14,  26,  22,  30,  42,  48,  38,  58,  60,  72,  62,
         68,  72,  58,  76,  86,  90, 100], dtype=int64))
```

---

### ğŸ’» ì…€ 7 - ì½”ë“œ

```python
from sklearn.linear_model import LinearRegression
reg = LinearRegression() # ê°ì²´ ìƒì„±
reg.fit(X, y) # í•™ìŠµ (ëª¨ë¸ ìƒì„±)
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
LinearRegression()
```

---

### ğŸ’» ì…€ 8 - ì½”ë“œ

```python
y_pred = reg.predict(X) # X ì— ëŒ€í•œ ì˜ˆì¸¡ ê°’
y_pred
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
array([  5.00336377,  12.31395163,  18.58016979,  24.84638795,
        26.93512734,  33.20134551,  40.51193337,  45.73378184,
        46.77815153,  52.        ,  55.13310908,  60.35495755,
        62.44369694,  63.48806663,  64.53243633,  71.84302419,
        74.97613327,  87.5085696 ,  89.59730899, 104.2184847 ])
```

---

### ğŸ’» ì…€ 9 - ì½”ë“œ

```python
plt.scatter(X, y, color='blue') # ì‚°ì ë„
plt.plot(X, y_pred, color='green') # ì„  ê·¸ë˜í”„
plt.title('Score by hours') # ì œëª©
plt.xlabel('hours') # X ì¶• ì´ë¦„
plt.ylabel('score') # Y ì¶• ì´ë¦„
plt.show()
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
<Figure size 432x288 with 1 Axes>
```

---

### ğŸ’» ì…€ 10 - ì½”ë“œ

```python
print('9ì‹œê°„ ê³µë¶€í–ˆì„ ë•Œ ì˜ˆìƒ ì ìˆ˜ : ', reg.predict([[9]])) # [[9], [8], [7]]
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
9ì‹œê°„ ê³µë¶€í–ˆì„ ë•Œ ì˜ˆìƒ ì ìˆ˜ :  [93.77478776]
```

---

### ğŸ’» ì…€ 11 - ì½”ë“œ

```python
reg.coef_ # ê¸°ìš¸ê¸° (m)
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
array([10.44369694])
```

---

### ğŸ’» ì…€ 12 - ì½”ë“œ

```python
reg.intercept_ # y ì ˆí¸ (b)
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
-0.21848470286721522
```

---

### ğŸ“ ì…€ 13 - ë§ˆí¬ë‹¤ìš´

y = mx + b  -> y = 10.4436x - 0.2184

---

### ğŸ“ ì…€ 14 - ë§ˆí¬ë‹¤ìš´

### ë°ì´í„° ì„¸íŠ¸ ë¶„ë¦¬

---

### ğŸ’» ì…€ 15 - ì½”ë“œ

```python
import matplotlib.pyplot as plt
import pandas as pd
```

---

### ğŸ’» ì…€ 16 - ì½”ë“œ

```python
dataset = pd.read_csv('LinearRegressionData.csv')
dataset
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
hour  score
0    0.5     10
1    1.2      8
2    1.8     14
3    2.4     26
4    2.6     22
5    3.2     30
6    3.9     42
7    4.4     48
8    4.5     38
9    5.0     58
10   5.3     60
11   5.8     72
12   6.0     62
13   6.1     68
14   6.2     72
15   6.9     58
16   7.2     76
17   8.4     86
18   8.6     90
19  10.0    100
```

---

### ğŸ’» ì…€ 17 - ì½”ë“œ

```python
X = dataset.iloc[:, :-1].values
y = dataset.iloc[:, -1].values
```

---

### ğŸ’» ì…€ 18 - ì½”ë“œ

```python
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0) # í›ˆë ¨ 80 : í…ŒìŠ¤íŠ¸ 20 ìœ¼ë¡œ ë¶„ë¦¬
```

---

### ğŸ’» ì…€ 19 - ì½”ë“œ

```python
X, len(X) # ì „ì²´ ë°ì´í„° X, ê°œìˆ˜
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
(array([[ 0.5],
        [ 1.2],
        [ 1.8],
        [ 2.4],
        [ 2.6],
        [ 3.2],
        [ 3.9],
        [ 4.4],
        [ 4.5],
        [ 5. ],
        [ 5.3],
        [ 5.8],
        [ 6. ],
        [ 6.1],
        [ 6.2],
        [ 6.9],
        [ 7.2],
        [ 8.4],
        [ 8.6],
        [10. ]]),
 20)
```

---

### ğŸ’» ì…€ 20 - ì½”ë“œ

```python
X_train, len(X_train) # í›ˆë ¨ ì„¸íŠ¸ X, ê°œìˆ˜
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
(array([[5.3],
        [8.4],
        [3.9],
        [6.1],
        [2.6],
        [1.8],
        [3.2],
        [6.2],
        [5. ],
        [4.4],
        [7.2],
        [5.8],
        [2.4],
        [0.5],
        [6.9],
        [6. ]]),
 16)
```

---

### ğŸ’» ì…€ 21 - ì½”ë“œ

```python
X_test, len(X_test) # í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ X, ê°œìˆ˜
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
(array([[ 8.6],
        [ 1.2],
        [10. ],
        [ 4.5]]),
 4)
```

---

### ğŸ’» ì…€ 22 - ì½”ë“œ

```python
y, len(y) # ì „ì²´ ë°ì´í„° y
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
(array([ 10,   8,  14,  26,  22,  30,  42,  48,  38,  58,  60,  72,  62,
         68,  72,  58,  76,  86,  90, 100], dtype=int64),
 20)
```

---

### ğŸ’» ì…€ 23 - ì½”ë“œ

```python
y_train, len(y_train) # í›ˆë ¨ ì„¸íŠ¸ y
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
(array([60, 86, 42, 68, 22, 14, 30, 72, 58, 48, 76, 72, 26, 10, 58, 62],
       dtype=int64),
 16)
```

---

### ğŸ’» ì…€ 24 - ì½”ë“œ

```python
y_test, len(y_test) # í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ y
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
(array([ 90,   8, 100,  38], dtype=int64), 4)
```

---

### ğŸ“ ì…€ 25 - ë§ˆí¬ë‹¤ìš´

### ë¶„ë¦¬ëœ ë°ì´í„°ë¥¼ í†µí•œ ëª¨ë¸ë§

---

### ğŸ’» ì…€ 26 - ì½”ë“œ

```python
from sklearn.linear_model import LinearRegression
reg = LinearRegression()
```

---

### ğŸ’» ì…€ 27 - ì½”ë“œ

```python
reg.fit(X_train, y_train) # í›ˆë ¨ ì„¸íŠ¸ë¡œ í•™ìŠµ
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
LinearRegression()
```

---

### ğŸ“ ì…€ 28 - ë§ˆí¬ë‹¤ìš´

### ë°ì´í„° ì‹œê°í™” (í›ˆë ¨ ì„¸íŠ¸)

---

### ğŸ’» ì…€ 29 - ì½”ë“œ

```python
plt.scatter(X_train, y_train, color='blue') # ì‚°ì ë„
plt.plot(X_train, reg.predict(X_train), color='green') # ì„  ê·¸ë˜í”„
plt.title('Score by hours (train data)') # ì œëª©
plt.xlabel('hours') # X ì¶• ì´ë¦„
plt.ylabel('score') # Y ì¶• ì´ë¦„
plt.show()
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
<Figure size 432x288 with 1 Axes>
```

---

### ğŸ“ ì…€ 30 - ë§ˆí¬ë‹¤ìš´

### ë°ì´í„° ì‹œê°í™” (í…ŒìŠ¤íŠ¸ ì„¸íŠ¸)

---

### ğŸ’» ì…€ 31 - ì½”ë“œ

```python
plt.scatter(X_test, y_test, color='blue') # ì‚°ì ë„
plt.plot(X_train, reg.predict(X_train), color='green') # ì„  ê·¸ë˜í”„
plt.title('Score by hours (test data)') # ì œëª©
plt.xlabel('hours') # X ì¶• ì´ë¦„
plt.ylabel('score') # Y ì¶• ì´ë¦„
plt.show()
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
<Figure size 432x288 with 1 Axes>
```

---

### ğŸ’» ì…€ 32 - ì½”ë“œ

```python
reg.coef_
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
array([10.49161294])
```

---

### ğŸ’» ì…€ 33 - ì½”ë“œ

```python
reg.intercept_
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
0.6115562905169796
```

---

### ğŸ“ ì…€ 34 - ë§ˆí¬ë‹¤ìš´

### ëª¨ë¸ í‰ê°€

---

### ğŸ’» ì…€ 35 - ì½”ë“œ

```python
reg.score(X_test, y_test) # í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¥¼ í†µí•œ ëª¨ë¸ í‰ê°€
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
0.9727616474310156
```

---

### ğŸ’» ì…€ 36 - ì½”ë“œ

```python
reg.score(X_train, y_train) # í›ˆë ¨ ì„¸íŠ¸ë¥¼ í†µí•œ ëª¨ë¸ í‰ê°€
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
0.9356663661221668
```

---

### ğŸ“ ì…€ 37 - ë§ˆí¬ë‹¤ìš´

## ê²½ì‚¬ í•˜ê°•ë²• (Gradient Descent)

---

### ğŸ“ ì…€ 38 - ë§ˆí¬ë‹¤ìš´

max_iter : í›ˆë ¨ ì„¸íŠ¸ ë°˜ë³µ íšŸìˆ˜ (Epoch íšŸìˆ˜)

eta0 : í•™ìŠµë¥  (learning rate)

---

### ğŸ’» ì…€ 39 - ì½”ë“œ

```python
from sklearn.linear_model import SGDRegressor # SGD : Stochastic Gradient Descent í™•ë¥ ì  ê²½ì‚¬ í•˜ê°•ë²•

# ì§€ìˆ˜í‘œê¸°ë²•
# 1e-3 : 0.001 (10^-3)
# 1e-4 : 0.0001 (10^-4)
# 1e+3 : 1000 (10^3)
# 1e+4 : 10000 (10^4)

# sr = SGDRegressor(max_iter=200, eta0=1e-4, random_state=0, verbose=1)
sr = SGDRegressor()
sr.fit(X_train, y_train)
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
SGDRegressor()
```

---

### ğŸ’» ì…€ 40 - ì½”ë“œ

```python
plt.scatter(X_train, y_train, color='blue') # ì‚°ì ë„
plt.plot(X_train, sr.predict(X_train), color='green') # ì„  ê·¸ë˜í”„
plt.title('Score by hours (train data, SGD)') # ì œëª©
plt.xlabel('hours') # X ì¶• ì´ë¦„
plt.ylabel('score') # Y ì¶• ì´ë¦„
plt.show()
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
<Figure size 432x288 with 1 Axes>
```

---

### ğŸ’» ì…€ 41 - ì½”ë“œ

```python
sr.coef_, sr.intercept_
# ì£¼ì˜ : SGDRegressor() ê°ì²´ë¥¼ ìƒì„±í•  ë•Œ random_state ê°’ì„ ì§€ì •í•˜ì§€ ì•Šì•˜ìœ¼ë¯€ë¡œ ê²°ê³¼ê°€ ë‹¤ë¥´ê²Œ ë‚˜íƒ€ë‚  ìˆ˜ ìˆìŠµë‹ˆë‹¤
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
(array([10.2062811]), array([1.95017289]))
```

---

### ğŸ’» ì…€ 42 - ì½”ë“œ

```python
sr.score(X_test, y_test) # í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¥¼ í†µí•œ ëª¨ë¸ í‰ê°€ 
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
0.9732274354250781
```

---

### ğŸ’» ì…€ 43 - ì½”ë“œ

```python
sr.score(X_train, y_train) # í›ˆë ¨ ì„¸íŠ¸ë¥¼ í†µí•œ ëª¨ë¸ í‰ê°€ 
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
0.9349740699430755
```

---


## ğŸ““ 02. Multiple Linear Regression.ipynb

> **íŒŒì¼ ê²½ë¡œ**: `C:\pythonworkspace\02. Multiple Linear Regression.ipynb`
> **ì´ ì…€ ê°œìˆ˜**: 24ê°œ

### ğŸ“ ì…€ 1 - ë§ˆí¬ë‹¤ìš´

# 2. Multiple Linear Regression

---

### ğŸ“ ì…€ 2 - ë§ˆí¬ë‹¤ìš´

### ì›-í•« ì¸ì½”ë”©

---

### ğŸ’» ì…€ 3 - ì½”ë“œ

```python
import pandas as pd
```

---

### ğŸ’» ì…€ 4 - ì½”ë“œ

```python
dataset = pd.read_csv('MultipleLinearRegressionData.csv')
X = dataset.iloc[:, :-1].values
y = dataset.iloc[:, -1].values
```

---

### ğŸ’» ì…€ 5 - ì½”ë“œ

```python
X
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
array([[0.5, 3, 'Home'],
       [1.2, 4, 'Library'],
       [1.8, 2, 'Cafe'],
       [2.4, 0, 'Cafe'],
       [2.6, 2, 'Home'],
       [3.2, 0, 'Home'],
       [3.9, 0, 'Library'],
       [4.4, 0, 'Library'],
       [4.5, 5, 'Home'],
       [5.0, 1, 'Cafe'],
       [5.3, 2, 'Cafe'],
       [5.8, 0, 'Cafe'],
       [6.0, 3, 'Library'],
       [6.1, 1, 'Cafe'],
       [6.2, 1, 'Library'],
       [6.9, 4, 'Home'],
       [7.2, 2, 'Cafe'],
       [8.4, 1, 'Home'],
       [8.6, 1, 'Library'],
       [10.0, 0, 'Library']], dtype=object)
```

---

### ğŸ’» ì…€ 6 - ì½”ë“œ

```python
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder
ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(drop='first'), [2])], remainder='passthrough')
X = ct.fit_transform(X)
X

# 1 0 : Home
# 0 1 : Library
# 0 0 : Cafe
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
array([[1.0, 0.0, 0.5, 3],
       [0.0, 1.0, 1.2, 4],
       [0.0, 0.0, 1.8, 2],
       [0.0, 0.0, 2.4, 0],
       [1.0, 0.0, 2.6, 2],
       [1.0, 0.0, 3.2, 0],
       [0.0, 1.0, 3.9, 0],
       [0.0, 1.0, 4.4, 0],
       [1.0, 0.0, 4.5, 5],
       [0.0, 0.0, 5.0, 1],
       [0.0, 0.0, 5.3, 2],
       [0.0, 0.0, 5.8, 0],
       [0.0, 1.0, 6.0, 3],
       [0.0, 0.0, 6.1, 1],
       [0.0, 1.0, 6.2, 1],
       [1.0, 0.0, 6.9, 4],
       [0.0, 0.0, 7.2, 2],
       [1.0, 0.0, 8.4, 1],
       [0.0, 1.0, 8.6, 1],
       [0.0, 1.0, 10.0, 0]], dtype=object)
```

---

### ğŸ“ ì…€ 7 - ë§ˆí¬ë‹¤ìš´

### ë°ì´í„° ì„¸íŠ¸ ë¶„ë¦¬

---

### ğŸ’» ì…€ 8 - ì½”ë“œ

```python
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)
```

---

### ğŸ“ ì…€ 9 - ë§ˆí¬ë‹¤ìš´

### í•™ìŠµ (ë‹¤ì¤‘ ì„ í˜• íšŒê·€)

---

### ğŸ’» ì…€ 10 - ì½”ë“œ

```python
from sklearn.linear_model import LinearRegression
reg = LinearRegression()
reg.fit(X_train, y_train)
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
LinearRegression()
```

---

### ğŸ“ ì…€ 11 - ë§ˆí¬ë‹¤ìš´

### ì˜ˆì¸¡ ê°’ê³¼ ì‹¤ì œ ê°’ ë¹„êµ (í…ŒìŠ¤íŠ¸ ì„¸íŠ¸)

---

### ğŸ’» ì…€ 12 - ì½”ë“œ

```python
y_pred = reg.predict(X_test)
y_pred
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
array([ 92.15457859,  10.23753043, 108.36245302,  38.14675204])
```

---

### ğŸ’» ì…€ 13 - ì½”ë“œ

```python
y_test
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
array([ 90,   8, 100,  38], dtype=int64)
```

---

### ğŸ’» ì…€ 14 - ì½”ë“œ

```python
reg.coef_
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
array([-5.82712824, -1.04450647, 10.40419528, -1.64200104])
```

---

### ğŸ’» ì…€ 15 - ì½”ë“œ

```python
reg.intercept_
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
5.365006706544747
```

---

### ğŸ“ ì…€ 16 - ë§ˆí¬ë‹¤ìš´

### ëª¨ë¸ í‰ê°€

---

### ğŸ’» ì…€ 17 - ì½”ë“œ

```python
reg.score(X_train, y_train) # í›ˆë ¨ ì„¸íŠ¸
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
0.9623352565265527
```

---

### ğŸ’» ì…€ 18 - ì½”ë“œ

```python
reg.score(X_test, y_test) # í…ŒìŠ¤íŠ¸ ì„¸íŠ¸
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
0.9859956178877445
```

---

### ğŸ“ ì…€ 19 - ë§ˆí¬ë‹¤ìš´

### ë‹¤ì–‘í•œ í‰ê°€ ì§€í‘œ (íšŒê·€ ëª¨ë¸)

---

### ğŸ“ ì…€ 20 - ë§ˆí¬ë‹¤ìš´

1. MAE (Mean Absolute Error) : (ì‹¤ì œ ê°’ê³¼ ì˜ˆì¸¡ ê°’) ì°¨ì´ì˜ ì ˆëŒ€ê°’
1. MSE (Mean Squared Error) : ì°¨ì´ì˜ ì œê³±
1. RMSE (Root Mean Squared Error) : ì°¨ì´ì˜ ì œê³±ì— ë£¨íŠ¸
1. R2 : ê²°ì • ê³„ìˆ˜

> R2 ëŠ” 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡, ë‚˜ë¨¸ì§€ëŠ” 0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ìŒ

---

### ğŸ’» ì…€ 21 - ì½”ë“œ

```python
from sklearn.metrics import mean_absolute_error
mean_absolute_error(y_test, y_pred) # ì‹¤ì œ ê°’, ì˜ˆì¸¡ ê°’ # MAE
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
3.2253285188288023
```

---

### ğŸ’» ì…€ 22 - ì½”ë“œ

```python
from sklearn.metrics import mean_squared_error
mean_squared_error(y_test, y_pred) # MSE
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
19.900226981515015
```

---

### ğŸ’» ì…€ 23 - ì½”ë“œ

```python
from sklearn.metrics import mean_squared_error
mean_squared_error(y_test, y_pred, squared=False) # RMSE
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
4.460967045553578
```

---

### ğŸ’» ì…€ 24 - ì½”ë“œ

```python
from sklearn.metrics import r2_score
r2_score(y_test, y_pred) # R2
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
0.9859956178877445
```

---


## ğŸ““ 03. Polynomial Regression.ipynb

> **íŒŒì¼ ê²½ë¡œ**: `C:\pythonworkspace\03. Polynomial Regression.ipynb`
> **ì´ ì…€ ê°œìˆ˜**: 27ê°œ

### ğŸ“ ì…€ 1 - ë§ˆí¬ë‹¤ìš´

# 3. Polynomial Regression

---

### ğŸ“ ì…€ 2 - ë§ˆí¬ë‹¤ìš´

### ê³µë¶€ ì‹œê°„ì— ë”°ë¥¸ ì‹œí—˜ ì ìˆ˜ (ìš°ë“±ìƒ)

---

### ğŸ’» ì…€ 3 - ì½”ë“œ

```python
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
```

---

### ğŸ’» ì…€ 4 - ì½”ë“œ

```python
dataset = pd.read_csv('PolynomialRegressionData.csv')
X = dataset.iloc[:, :-1].values
y = dataset.iloc[:, -1].values
```

---

### ğŸ“ ì…€ 5 - ë§ˆí¬ë‹¤ìš´

## 3-1. ë‹¨ìˆœ ì„ í˜• íšŒê·€ (Simple Linear Regression)

---

### ğŸ’» ì…€ 6 - ì½”ë“œ

```python
from sklearn.linear_model import LinearRegression
reg = LinearRegression()
reg.fit(X, y) # ì „ì²´ ë°ì´í„°ë¡œ í•™ìŠµ
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
LinearRegression()
```

---

### ğŸ“ ì…€ 7 - ë§ˆí¬ë‹¤ìš´

### ë°ì´í„° ì‹œê°í™” (ì „ì²´)

---

### ğŸ’» ì…€ 8 - ì½”ë“œ

```python
plt.scatter(X, y, color='blue') # ì‚°ì ë„
plt.plot(X, reg.predict(X), color='green') # ì„  ê·¸ë˜í”„
plt.title('Score by hours (genius)') # ì œëª©
plt.xlabel('hours') # X ì¶• ì´ë¦„
plt.ylabel('score') # Y ì¶• ì´ë¦„
plt.show()
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
<Figure size 432x288 with 1 Axes>
```

---

### ğŸ’» ì…€ 9 - ì½”ë“œ

```python
reg.score(X, y) # ì „ì²´ ë°ì´í„°ë¥¼ í†µí•œ ëª¨ë¸ í‰ê°€
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
0.8169296513411765
```

---

### ğŸ“ ì…€ 10 - ë§ˆí¬ë‹¤ìš´

## 3-2. ë‹¤í•­ íšŒê·€ (Polynomial Regression)

---

### ğŸ’» ì…€ 11 - ì½”ë“œ

```python
from sklearn.preprocessing import PolynomialFeatures
poly_reg = PolynomialFeatures(degree=4) # 2ì°¨
X_poly = poly_reg.fit_transform(X)
X_poly[:5] # [x] -> [x^0, x^1, x^2] -> x ê°€ 3ì´ë¼ë©´ [1, 3, 9] ìœ¼ë¡œ ë³€í™˜
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
array([[1.0000e+00, 2.0000e-01, 4.0000e-02, 8.0000e-03, 1.6000e-03],
       [1.0000e+00, 5.0000e-01, 2.5000e-01, 1.2500e-01, 6.2500e-02],
       [1.0000e+00, 8.0000e-01, 6.4000e-01, 5.1200e-01, 4.0960e-01],
       [1.0000e+00, 9.0000e-01, 8.1000e-01, 7.2900e-01, 6.5610e-01],
       [1.0000e+00, 1.2000e+00, 1.4400e+00, 1.7280e+00, 2.0736e+00]])
```

---

### ğŸ’» ì…€ 12 - ì½”ë“œ

```python
X[:5]
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
array([[0.2],
       [0.5],
       [0.8],
       [0.9],
       [1.2]])
```

---

### ğŸ’» ì…€ 13 - ì½”ë“œ

```python
poly_reg.get_feature_names_out()
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
array(['1', 'x0', 'x0^2', 'x0^3', 'x0^4'], dtype=object)
```

---

### ğŸ’» ì…€ 14 - ì½”ë“œ

```python
lin_reg = LinearRegression()
lin_reg.fit(X_poly, y) # ë³€í™˜ëœ X ì™€ y ë¥¼ ê°€ì§€ê³  ëª¨ë¸ ìƒì„± (í•™ìŠµ)
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
LinearRegression()
```

---

### ğŸ“ ì…€ 15 - ë§ˆí¬ë‹¤ìš´

### ë°ì´í„° ì‹œê°í™” (ë³€í™˜ëœ X ì™€ y)

---

### ğŸ’» ì…€ 16 - ì½”ë“œ

```python
plt.scatter(X, y, color='blue')
plt.plot(X, lin_reg.predict(poly_reg.fit_transform(X)), color='green')
plt.title('Score by hours (genius)') # ì œëª©
plt.xlabel('hours') # X ì¶• ì´ë¦„
plt.ylabel('score') # Y ì¶• ì´ë¦„
plt.show()
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
<Figure size 432x288 with 1 Axes>
```

---

### ğŸ’» ì…€ 17 - ì½”ë“œ

```python
X_range = np.arange(min(X), max(X), 0.1) # X ì˜ ìµœì†Œê°’ì—ì„œ ìµœëŒ€ê°’ê¹Œì§€ì˜ ë²”ìœ„ë¥¼ 0.1 ë‹¨ìœ„ë¡œ ì˜ë¼ì„œ ë°ì´í„°ë¥¼ ìƒì„±
X_range
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
array([0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. , 1.1, 1.2, 1.3, 1.4,
       1.5, 1.6, 1.7, 1.8, 1.9, 2. , 2.1, 2.2, 2.3, 2.4, 2.5, 2.6, 2.7,
       2.8, 2.9, 3. , 3.1, 3.2, 3.3, 3.4, 3.5, 3.6, 3.7, 3.8, 3.9, 4. ,
       4.1, 4.2, 4.3, 4.4, 4.5, 4.6, 4.7])
```

---

### ğŸ’» ì…€ 18 - ì½”ë“œ

```python
X_range.shape
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
(46,)
```

---

### ğŸ’» ì…€ 19 - ì½”ë“œ

```python
X[:5]
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
array([[0.2],
       [0.5],
       [0.8],
       [0.9],
       [1.2]])
```

---

### ğŸ’» ì…€ 20 - ì½”ë“œ

```python
X.shape
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
(20, 1)
```

---

### ğŸ’» ì…€ 21 - ì½”ë“œ

```python
X_range = X_range.reshape(-1, 1) # row ê°œìˆ˜ëŠ” ìë™ìœ¼ë¡œ ê³„ì‚°, column ê°œìˆ˜ëŠ” 1ê°œ
X_range.shape
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
(46, 1)
```

---

### ğŸ’» ì…€ 22 - ì½”ë“œ

```python
X_range[:5]
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
array([[0.2],
       [0.3],
       [0.4],
       [0.5],
       [0.6]])
```

---

### ğŸ’» ì…€ 23 - ì½”ë“œ

```python
plt.scatter(X, y, color='blue')
plt.plot(X_range, lin_reg.predict(poly_reg.fit_transform(X_range)), color='green')
plt.title('Score by hours (genius)') # ì œëª©
plt.xlabel('hours') # X ì¶• ì´ë¦„
plt.ylabel('score') # Y ì¶• ì´ë¦„
plt.show()
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
<Figure size 432x288 with 1 Axes>
```

---

### ğŸ“ ì…€ 24 - ë§ˆí¬ë‹¤ìš´

### ê³µë¶€ ì‹œê°„ì— ë”°ë¥¸ ì‹œí—˜ ì„±ì  ì˜ˆì¸¡

---

### ğŸ’» ì…€ 25 - ì½”ë“œ

```python
reg.predict([[2]]) # 2ì‹œê°„ì„ ê³µë¶€í–ˆì„ ë•Œ ì„ í˜• íšŒê·€ ëª¨ë¸ì˜ ì˜ˆì¸¡
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
array([19.85348988])
```

---

### ğŸ’» ì…€ 26 - ì½”ë“œ

```python
lin_reg.predict(poly_reg.fit_transform([[2]])) # 2ì‹œê°„ì„ ê³µë¶€í–ˆì„ ë•Œ ë‹¤í•­ íšŒê·€ ëª¨ë¸ì˜ ì˜ˆì¸¡
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
array([8.70559135])
```

---

### ğŸ’» ì…€ 27 - ì½”ë“œ

```python
lin_reg.score(X_poly, y)
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
0.9782775579000045
```

---


## ğŸ““ 04. Logistic Regression.ipynb

> **íŒŒì¼ ê²½ë¡œ**: `C:\pythonworkspace\04. Logistic Regression.ipynb`
> **ì´ ì…€ ê°œìˆ˜**: 31ê°œ

### ğŸ“ ì…€ 1 - ë§ˆí¬ë‹¤ìš´

# 4. Logistic Regression

---

### ğŸ“ ì…€ 2 - ë§ˆí¬ë‹¤ìš´

### ê³µë¶€ ì‹œê°„ì— ë”°ë¥¸ ìê²©ì¦ ì‹œí—˜ í•©ê²© ê°€ëŠ¥ì„±

---

### ğŸ’» ì…€ 3 - ì½”ë“œ

```python
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
```

---

### ğŸ’» ì…€ 4 - ì½”ë“œ

```python
dataset = pd.read_csv('LogisticRegressionData.csv')
X = dataset.iloc[:, :-1].values
y = dataset.iloc[:, -1].values
```

---

### ğŸ“ ì…€ 5 - ë§ˆí¬ë‹¤ìš´

### ë°ì´í„° ë¶„ë¦¬

---

### ğŸ’» ì…€ 6 - ì½”ë“œ

```python
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)
```

---

### ğŸ“ ì…€ 7 - ë§ˆí¬ë‹¤ìš´

### í•™ìŠµ (ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨ë¸)

---

### ğŸ’» ì…€ 8 - ì½”ë“œ

```python
from sklearn.linear_model import LogisticRegression
classifier = LogisticRegression()
classifier.fit(X_train, y_train)
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
LogisticRegression()
```

---

### ğŸ“ ì…€ 9 - ë§ˆí¬ë‹¤ìš´

### 6ì‹œê°„ ê³µë¶€í–ˆì„ ë•Œ ì˜ˆì¸¡?

---

### ğŸ’» ì…€ 10 - ì½”ë“œ

```python
classifier.predict([[6]])
# ê²°ê³¼ 1 : í•©ê²©í•  ê²ƒìœ¼ë¡œ ì˜ˆì¸¡
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
array([1], dtype=int64)
```

---

### ğŸ’» ì…€ 11 - ì½”ë“œ

```python
classifier.predict_proba([[6]]) # í•©ê²©í•  í™•ë¥  ì¶œë ¥
# ë¶ˆí•©ê²© í™•ë¥  14%, í•©ê²© í™•ë¥  86%
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
array([[0.14150735, 0.85849265]])
```

---

### ğŸ“ ì…€ 12 - ë§ˆí¬ë‹¤ìš´

### 4ì‹œê°„ ê³µë¶€í–ˆì„ ë•Œ ì˜ˆì¸¡?

---

### ğŸ’» ì…€ 13 - ì½”ë“œ

```python
classifier.predict([[4]])
# ê²°ê³¼ 0 : ë¶ˆí•©ê²©í•  ê²ƒìœ¼ë¡œ ì˜ˆì¸¡
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
array([0], dtype=int64)
```

---

### ğŸ’» ì…€ 14 - ì½”ë“œ

```python
classifier.predict_proba([[4]]) # í•©ê²©í•  í™•ë¥  ì¶œë ¥
# ë¶ˆí•©ê²© í™•ë¥  62%, í•©ê²© í™•ë¥  38%
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
array([[0.6249966, 0.3750034]])
```

---

### ğŸ“ ì…€ 15 - ë§ˆí¬ë‹¤ìš´

### ë¶„ë¥˜ ê²°ê³¼ ì˜ˆì¸¡ (í…ŒìŠ¤íŠ¸ ì„¸íŠ¸)

---

### ğŸ’» ì…€ 16 - ì½”ë“œ

```python
y_pred = classifier.predict(X_test)
y_pred # ì˜ˆì¸¡ ê°’
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
array([1, 0, 1, 1], dtype=int64)
```

---

### ğŸ’» ì…€ 17 - ì½”ë“œ

```python
y_test # ì‹¤ì œ ê°’ (í…ŒìŠ¤íŠ¸ ì„¸íŠ¸)
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
array([1, 0, 1, 0], dtype=int64)
```

---

### ğŸ’» ì…€ 18 - ì½”ë“œ

```python
X_test # ê³µë¶€ ì‹œê°„ (í…ŒìŠ¤íŠ¸ ì„¸íŠ¸)
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
array([[ 8.6],
       [ 1.2],
       [10. ],
       [ 4.5]])
```

---

### ğŸ’» ì…€ 19 - ì½”ë“œ

```python
classifier.score(X_test, y_test) # ëª¨ë¸ í‰ê°€
# ì „ì²´ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ 4ê°œ ì¤‘ì—ì„œ ë¶„ë¥˜ ì˜ˆì¸¡ì„ ì˜¬ë°”ë¡œ ë§íŒ ê°œìˆ˜ 3ê°œ -> 3/4 = 0.75
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
0.75
```

---

### ğŸ“ ì…€ 20 - ë§ˆí¬ë‹¤ìš´

### ë°ì´í„° ì‹œê°í™” (í›ˆë ¨ ì„¸íŠ¸)

---

### ğŸ’» ì…€ 21 - ì½”ë“œ

```python
X_range = np.arange(min(X), max(X), 0.1) # X ì˜ ìµœì†Œê°’ì—ì„œ ìµœëŒ€ê°’ê¹Œì§€ë¥¼ 0.1 ë‹¨ìœ„ë¡œ ì˜ë¼ì„œ ë°ì´í„° ìƒì„±
X_range
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
array([0.5, 0.6, 0.7, 0.8, 0.9, 1. , 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7,
       1.8, 1.9, 2. , 2.1, 2.2, 2.3, 2.4, 2.5, 2.6, 2.7, 2.8, 2.9, 3. ,
       3.1, 3.2, 3.3, 3.4, 3.5, 3.6, 3.7, 3.8, 3.9, 4. , 4.1, 4.2, 4.3,
       4.4, 4.5, 4.6, 4.7, 4.8, 4.9, 5. , 5.1, 5.2, 5.3, 5.4, 5.5, 5.6,
       5.7, 5.8, 5.9, 6. , 6.1, 6.2, 6.3, 6.4, 6.5, 6.6, 6.7, 6.8, 6.9,
       7. , 7.1, 7.2, 7.3, 7.4, 7.5, 7.6, 7.7, 7.8, 7.9, 8. , 8.1, 8.2,
       8.3, 8.4, 8.5, 8.6, 8.7, 8.8, 8.9, 9. , 9.1, 9.2, 9.3, 9.4, 9.5,
       9.6, 9.7, 9.8, 9.9])
```

---

### ğŸ’» ì…€ 22 - ì½”ë“œ

```python
p = 1 / (1 + np.exp(-(classifier.coef_ * X_range + classifier.intercept_))) # y = mx + b
p
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
array([[0.01035705, 0.01161247, 0.01301807, 0.0145913 , 0.01635149,
        0.01832008, 0.02052073, 0.02297953, 0.02572521, 0.02878929,
        0.03220626, 0.03601375, 0.04025264, 0.04496719, 0.05020505,
        0.05601722, 0.06245802, 0.06958479, 0.07745757, 0.08613861,
        0.09569165, 0.10618106, 0.11767067, 0.13022241, 0.14389468,
        0.15874043, 0.17480509, 0.19212422, 0.2107211 , 0.23060425,
        0.25176509, 0.27417574, 0.29778732, 0.32252874, 0.34830616,
        0.3750034 , 0.40248315, 0.43058927, 0.45914989, 0.48798142,
        0.51689314, 0.54569221, 0.57418876, 0.60220088, 0.6295591 ,
        0.65611024, 0.68172044, 0.70627722, 0.72969059, 0.75189324,
        0.77283994, 0.79250621, 0.81088652, 0.82799203, 0.84384828,
        0.85849265, 0.871972  , 0.88434036, 0.89565683, 0.90598377,
        0.91538521, 0.92392546, 0.93166808, 0.93867499, 0.9450058 ,
        0.95071738, 0.95586346, 0.96049453, 0.96465764, 0.96839647,
        0.97175136, 0.97475939, 0.97745455, 0.97986786, 0.9820276 ,
        0.98395944, 0.98568665, 0.9872303 , 0.98860939, 0.98984107,
        0.9909408 , 0.99192244, 0.99279849, 0.99358014, 0.99427745,
        0.9948994 , 0.99545406, 0.99594865, 0.99638963, 0.99678276,
        0.99713321, 0.99744558, 0.997724  , 0.99797213, 0.99819325]])
```

---

### ğŸ’» ì…€ 23 - ì½”ë“œ

```python
p.shape
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
(1, 95)
```

---

### ğŸ’» ì…€ 24 - ì½”ë“œ

```python
X_range.shape
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
(95,)
```

---

### ğŸ’» ì…€ 25 - ì½”ë“œ

```python
p = p.reshape(-1) # 1ì°¨ì› ë°°ì—´ í˜•íƒœë¡œ ë³€ê²½
p.shape
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
(95,)
```

---

### ğŸ’» ì…€ 26 - ì½”ë“œ

```python
plt.scatter(X_train, y_train, color='blue')
plt.plot(X_range, p, color='green')
plt.plot(X_range, np.full(len(X_range), 0.5), color='red') # X_range ê°œìˆ˜ë§Œí¼ 0.5 ë¡œ ê°€ë“ì°¬ ë°°ì—´ ë§Œë“¤ê¸°
plt.title('Probability by hours')
plt.xlabel('hours')
plt.ylabel('P')
plt.show()
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
<Figure size 432x288 with 1 Axes>
```

---

### ğŸ“ ì…€ 27 - ë§ˆí¬ë‹¤ìš´

### ë°ì´í„° ì‹œê°í™” (í…ŒìŠ¤íŠ¸ ì„¸íŠ¸)

---

### ğŸ’» ì…€ 28 - ì½”ë“œ

```python
plt.scatter(X_test, y_test, color='blue')
plt.plot(X_range, p, color='green')
plt.plot(X_range, np.full(len(X_range), 0.5), color='red') # X_range ê°œìˆ˜ë§Œí¼ 0.5 ë¡œ ê°€ë“ì°¬ ë°°ì—´ ë§Œë“¤ê¸°
plt.title('Probability by hours (test)')
plt.xlabel('hours')
plt.ylabel('P')
plt.show()
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
<Figure size 432x288 with 1 Axes>
```

---

### ğŸ’» ì…€ 29 - ì½”ë“œ

```python
classifier.predict_proba([[4.5]]) # 4.5 ì‹œê°„ ê³µë¶€í–ˆì„ ë•Œ í™•ë¥  (ëª¨ë¸ì—ì„œëŠ” 51% í™•ë¥ ë¡œ í•©ê²© ì˜ˆì¸¡, ì‹¤ì œë¡œëŠ” ë¶ˆí•©ê²©)
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
array([[0.48310686, 0.51689314]])
```

---

### ğŸ“ ì…€ 30 - ë§ˆí¬ë‹¤ìš´

### í˜¼ë™ í–‰ë ¬ (Confusion Matrix)

---

### ğŸ’» ì…€ 31 - ì½”ë“œ

```python
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_pred)
cm

# TRUE NEGATIVE (TN)       FALSE POSITIVE (FP)
# ë¶ˆí•©ê²©ì¼ê±°ì•¼ (ì˜ˆì¸¡)      í•©ê²©ì¼ê±°ì•¼ (ì˜ˆì¸¡)
# ë¶ˆí•©ê²© (ì‹¤ì œ)             ë¶ˆí•©ê²© (ì‹¤ì œ)

# FALSE NEGATIVE (FN)      TRUE POSITIVE (TP)
# ë¶ˆí•©ê²©ì¼ê±°ì•¼ (ì˜ˆì¸¡)      í•©ê²©ì¼ê±°ì•¼ (ì˜ˆì¸¡)
# í•©ê²© (ì‹¤ì œ)               í•©ê²© (ì‹¤ì œ)
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
array([[1, 1],
       [0, 2]], dtype=int64)
```

---


## ğŸ““ 05. K-Means.ipynb

> **íŒŒì¼ ê²½ë¡œ**: `C:\pythonworkspace\05. K-Means.ipynb`
> **ì´ ì…€ ê°œìˆ˜**: 26ê°œ

### ğŸ“ ì…€ 1 - ë§ˆí¬ë‹¤ìš´

# 5. K-Means

---

### ğŸ’» ì…€ 2 - ì½”ë“œ

```python
import os # ê²½ê³  ëŒ€ì‘
os.environ['OMP_NUM_THREADS'] = '1'
```

---

### ğŸ’» ì…€ 3 - ì½”ë“œ

```python
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
```

---

### ğŸ’» ì…€ 4 - ì½”ë“œ

```python
dataset = pd.read_csv('KMeansData.csv')
dataset[:5]
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
hour  score
0  7.33     73
1  3.71     55
2  3.43     55
3  3.06     89
4  3.33     79
```

---

### ğŸ’» ì…€ 5 - ì½”ë“œ

```python
X = dataset.iloc[:, :].values
# X = dataset.values
# X = dataset.to_numpy() # ê³µì‹ í™ˆí˜ì´ì§€ ê¶Œì¥
X[:5]
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
array([[ 7.33, 73.  ],
       [ 3.71, 55.  ],
       [ 3.43, 55.  ],
       [ 3.06, 89.  ],
       [ 3.33, 79.  ]])
```

---

### ğŸ“ ì…€ 6 - ë§ˆí¬ë‹¤ìš´

### ë°ì´í„° ì‹œê°í™” (ì „ì²´ ë°ì´í„° ë¶„í¬ í™•ì¸)

---

### ğŸ’» ì…€ 7 - ì½”ë“œ

```python
plt.scatter(X[:, 0], X[:, 1]) # xì¶• : hour, yì¶• : score
plt.title('Score by hours')
plt.xlabel('hours')
plt.ylabel('score')
plt.show()
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
<Figure size 432x288 with 1 Axes>
```

---

### ğŸ“ ì…€ 8 - ë§ˆí¬ë‹¤ìš´

### ë°ì´í„° ì‹œê°í™” (ì¶• ë²”ìœ„ í†µì¼)

---

### ğŸ’» ì…€ 9 - ì½”ë“œ

```python
plt.scatter(X[:, 0], X[:, 1]) # xì¶• : hour, yì¶• : score
plt.title('Score by hours')
plt.xlabel('hours')
plt.xlim(0, 100)
plt.ylabel('score')
plt.ylim(0, 100)
plt.show()
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
<Figure size 432x288 with 1 Axes>
```

---

### ğŸ“ ì…€ 10 - ë§ˆí¬ë‹¤ìš´

### í”¼ì²˜ ìŠ¤ì¼€ì¼ë§ (Feature Scaling)

---

### ğŸ’» ì…€ 11 - ì½”ë“œ

```python
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X = sc.fit_transform(X)
X[:5]
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
array([[ 0.68729921,  0.73538376],
       [-0.66687438,  0.04198891],
       [-0.77161709,  0.04198891],
       [-0.9100271 ,  1.35173473],
       [-0.8090252 ,  0.96651537]])
```

---

### ğŸ“ ì…€ 12 - ë§ˆí¬ë‹¤ìš´

### ë°ì´í„° ì‹œê°í™” (ìŠ¤ì¼€ì¼ë§ëœ ë°ì´í„°)

---

### ğŸ’» ì…€ 13 - ì½”ë“œ

```python
plt.figure(figsize=(5, 5))
plt.scatter(X[:, 0], X[:, 1])
plt.title('Score by hours')
plt.xlabel('hours')
plt.ylabel('score')
plt.show()
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
<Figure size 360x360 with 1 Axes>
```

---

### ğŸ“ ì…€ 14 - ë§ˆí¬ë‹¤ìš´

### ìµœì ì˜ K ê°’ ì°¾ê¸° (ì—˜ë³´ìš° ë°©ì‹ Elbow Method)

---

### ğŸ’» ì…€ 15 - ì½”ë“œ

```python
from sklearn.cluster import KMeans
inertia_list = []
for i in range(1, 11):
    kmeans = KMeans(n_clusters=i, init='k-means++', random_state=0)
    kmeans.fit(X)
    inertia_list.append(kmeans.inertia_) # ê° ì§€ì ìœ¼ë¡œë¶€í„° í´ëŸ¬ìŠ¤í„°ì˜ ì¤‘ì‹¬(centroid) ê¹Œì§€ì˜ ê±°ë¦¬ì˜ ì œê³±ì˜ í•©
    
plt.plot(range(1, 11), inertia_list)
plt.title('Elbow Method')
plt.xlabel('n_clusters')
plt.ylabel('inertia')
plt.show()
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
<Figure size 432x288 with 1 Axes>
```

---

### ğŸ“ ì…€ 16 - ë§ˆí¬ë‹¤ìš´

### ìµœì ì˜ K (4) ê°’ìœ¼ë¡œ KMeans í•™ìŠµ

---

### ğŸ’» ì…€ 17 - ì½”ë“œ

```python
K = 4 # ìµœì ì˜ K ê°’
```

---

### ğŸ’» ì…€ 18 - ì½”ë“œ

```python
kmeans = KMeans(n_clusters=K, random_state=0)
# kmeans.fit(X)
y_kmeans = kmeans.fit_predict(X)
```

---

### ğŸ’» ì…€ 19 - ì½”ë“œ

```python
y_kmeans
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
array([2, 3, 3, 0, 0, 1, 1, 0, 2, 0, 0, 3, 1, 3, 3, 0, 1, 2, 3, 0, 1, 0,
       3, 1, 2, 2, 3, 3, 3, 3, 1, 1, 3, 0, 2, 2, 3, 0, 0, 0, 3, 1, 2, 3,
       3, 2, 1, 0, 1, 1, 2, 0, 1, 1, 0, 0, 0, 0, 3, 1, 1, 2, 2, 2, 2, 1,
       1, 0, 1, 2, 3, 2, 2, 2, 3, 3, 3, 3, 0, 2, 1, 2, 1, 1, 2, 0, 3, 1,
       2, 3, 0, 1, 0, 2, 3, 2, 2, 0, 1, 3])
```

---

### ğŸ“ ì…€ 20 - ë§ˆí¬ë‹¤ìš´

### ë°ì´í„° ì‹œê°í™” (ìµœì ì˜ K)

---

### ğŸ’» ì…€ 21 - ì½”ë“œ

```python
centers = kmeans.cluster_centers_ # í´ëŸ¬ìŠ¤í„°ì˜ ì¤‘ì‹¬ì  (centroid) ì¢Œí‘œ
centers
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
array([[-0.57163957,  0.85415973],
       [ 0.8837666 , -1.26929779],
       [ 0.94107583,  0.93569782],
       [-1.22698889, -0.46768593]])
```

---

### ğŸ’» ì…€ 22 - ì½”ë“œ

```python
for cluster in range(K):
    plt.scatter(X[y_kmeans == cluster, 0], X[y_kmeans == cluster, 1], s=100, edgecolor='black') # ê° ë°ì´í„°
    plt.scatter(centers[cluster, 0], centers[cluster, 1], s=300, edgecolor='black', color='yellow', marker='s') # ì¤‘ì‹¬ì  ë„¤ëª¨
    plt.text(centers[cluster, 0], centers[cluster, 1], cluster, va='center', ha='center') # í´ëŸ¬ìŠ¤í„° í…ìŠ¤íŠ¸ ì¶œë ¥
    
plt.title('Score by hours')
plt.xlabel('hours')
plt.ylabel('score')
plt.show()
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
<Figure size 432x288 with 1 Axes>
```

---

### ğŸ“ ì…€ 23 - ë§ˆí¬ë‹¤ìš´

### ë°ì´í„° ì‹œê°í™” (ìŠ¤ì¼€ì¼ë§ ì›ë³µ)

---

### ğŸ’» ì…€ 24 - ì½”ë“œ

```python
X_org = sc.inverse_transform(X) # Feature Scaling ëœ ë°ì´í„°ë¥¼ ë‹¤ì‹œ ì›ë³µ
X_org[:5]
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
array([[ 7.33, 73.  ],
       [ 3.71, 55.  ],
       [ 3.43, 55.  ],
       [ 3.06, 89.  ],
       [ 3.33, 79.  ]])
```

---

### ğŸ’» ì…€ 25 - ì½”ë“œ

```python
centers_org = sc.inverse_transform(centers)
centers_org
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
array([[ 3.96458333, 76.08333333],
       [ 7.8552    , 20.96      ],
       [ 8.0084    , 78.2       ],
       [ 2.21269231, 41.76923077]])
```

---

### ğŸ’» ì…€ 26 - ì½”ë“œ

```python
for cluster in range(K):
    plt.scatter(X_org[y_kmeans == cluster, 0], X_org[y_kmeans == cluster, 1], s=100, edgecolor='black') # ê° ë°ì´í„°
    plt.scatter(centers_org[cluster, 0], centers_org[cluster, 1], s=300, edgecolor='black', color='yellow', marker='s') # ì¤‘ì‹¬ì  ë„¤ëª¨
    plt.text(centers_org[cluster, 0], centers_org[cluster, 1], cluster, va='center', ha='center') # í´ëŸ¬ìŠ¤í„° í…ìŠ¤íŠ¸ ì¶œë ¥
    
plt.title('Score by hours')
plt.xlabel('hours')
plt.ylabel('score')
plt.show()
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
<Figure size 432x288 with 1 Axes>
```

---


## ğŸ““ 06. Quiz.ipynb

> **íŒŒì¼ ê²½ë¡œ**: `C:\pythonworkspace\06. Quiz.ipynb`
> **ì´ ì…€ ê°œìˆ˜**: 21ê°œ

### ğŸ“ ì…€ 1 - ë§ˆí¬ë‹¤ìš´

# 6. Quiz

---

### ğŸ“ ì…€ 2 - ë§ˆí¬ë‹¤ìš´

## ì–´ëŠ ê²°í˜¼ì‹ì¥ì—ì„œ í”¼ë¡œì—°ì˜ ì‹ìˆ˜ ì¸ì›ì„ ì˜¬ë°”ë¥´ê²Œ ì˜ˆì¸¡í•˜ì§€ ëª»í•˜ì—¬ ë²„ë ¤ì§€ëŠ” ìŒì‹ìœ¼ë¡œ ê³ ë¯¼ì´ ë§ë‹¤ê³  í•©ë‹ˆë‹¤. í˜„ì¬ê¹Œì§€ ì§„í–‰ëœ ê²°í˜¼ì‹ì— ëŒ€í•œ ê²°í˜¼ì‹ ì°¸ì„ ì¸ì›ê³¼ ê·¸ ì¤‘ì—ì„œ ì‹ì‚¬ë¥¼ í•˜ëŠ” ì¸ì›ì˜ ë°ì´í„°ê°€ ì œê³µë  ë•Œ, ì•„ë˜ ê° ë¬¸í•­ì— ëŒ€í•œ ì½”ë“œë¥¼ ì‘ì„±í•˜ì‹œì˜¤.

---

### ğŸ“ ì…€ 3 - ë§ˆí¬ë‹¤ìš´

ì£¼ì˜) ì‚¬ì „ ì‘ì—…ìœ¼ë¡œ ì•„ë˜ ì½”ë“œ ì…€ì„ ë¨¼ì € ì‹¤í–‰í•˜ì‹œì˜¤

---

### ğŸ’» ì…€ 4 - ì½”ë“œ

```python
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
```

---

### ğŸ“ ì…€ 5 - ë§ˆí¬ë‹¤ìš´

## 1) QuizData.csv íŒŒì¼ë¡œë¶€í„° ë°ì´í„°ë¥¼ ì½ì–´ì™€ì„œ ê²°í˜¼ì‹ ì°¸ì„ ì¸ì›(total), ì‹ìˆ˜ ì¸ì›(reception)ì„ ê°ê°ì˜ ë³€ìˆ˜ë¡œ ì €ì¥í•˜ì‹œì˜¤.

---

### ğŸ’» ì…€ 6 - ì½”ë“œ

```python
dataset = pd.read_csv('QuizData.csv')
dataset[:5]
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
total  reception
0    118         62
1    253        148
2    320        201
3     94         80
4    155         92
```

---

### ğŸ’» ì…€ 7 - ì½”ë“œ

```python
X = dataset.iloc[:, :-1].values # ê²°í˜¼ì‹ ì°¸ì„ ì¸ì› total
y = dataset.iloc[:, -1].values # ì‹ìˆ˜ ì¸ì› reception
```

---

### ğŸ’» ì…€ 8 - ì½”ë“œ

```python
X[:5], y[:5]
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
(array([[118],
        [253],
        [320],
        [ 94],
        [155]], dtype=int64),
 array([ 62, 148, 201,  80,  92], dtype=int64))
```

---

### ğŸ“ ì…€ 9 - ë§ˆí¬ë‹¤ìš´

## 2) ì „ì²´ ë°ì´í„°ë¥¼ í›ˆë ¨ ì„¸íŠ¸ì™€ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¡œ ë¶„ë¦¬í•˜ì‹œì˜¤. ì´ ë•Œ ë¹„ìœ¨ì€ 75 : 25 ë¡œ í•©ë‹ˆë‹¤.

(ë‹¨, random_state = 0 ìœ¼ë¡œ ì„¤ì •)

---

### ğŸ’» ì…€ 10 - ì½”ë“œ

```python
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)
```

---

### ğŸ“ ì…€ 11 - ë§ˆí¬ë‹¤ìš´

## 3) í›ˆë ¨ ì„¸íŠ¸ë¥¼ ì´ìš©í•˜ì—¬ ë‹¨ìˆœ ì„ í˜• íšŒê·€ (Simple Linear Regression) ëª¨ë¸ì„ ìƒì„±í•˜ì‹œì˜¤.

---

### ğŸ’» ì…€ 12 - ì½”ë“œ

```python
from sklearn.linear_model import LinearRegression
reg = LinearRegression()
reg.fit(X_train, y_train)
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
LinearRegression()
```

---

### ğŸ“ ì…€ 13 - ë§ˆí¬ë‹¤ìš´

## 4) ë°ì´í„° ì‹œê°í™” (í›ˆë ¨ ì„¸íŠ¸) ì½”ë“œë¥¼ ì‘ì„±í•˜ì‹œì˜¤.

---

### ğŸ’» ì…€ 14 - ì½”ë“œ

```python
plt.scatter(X_train, y_train, color='blue')
plt.plot(X_train, reg.predict(X_train), color='green')
plt.title('Wedding reception (train)')
plt.xlabel('total')
plt.ylabel('reception')
plt.show()
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
<Figure size 432x288 with 1 Axes>
```

---

### ğŸ“ ì…€ 15 - ë§ˆí¬ë‹¤ìš´

## 5) ë°ì´í„° ì‹œê°í™” (í…ŒìŠ¤íŠ¸ ì„¸íŠ¸) ì½”ë“œë¥¼ ì‘ì„±í•˜ì‹œì˜¤.

---

### ğŸ’» ì…€ 16 - ì½”ë“œ

```python
plt.scatter(X_test, y_test, color='blue')
plt.plot(X_train, reg.predict(X_train), color='green')
plt.title('Wedding reception (test)')
plt.xlabel('total')
plt.ylabel('reception')
plt.show()
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
<Figure size 432x288 with 1 Axes>
```

---

### ğŸ“ ì…€ 17 - ë§ˆí¬ë‹¤ìš´

## 6) í›ˆë ¨ ì„¸íŠ¸, í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì— ëŒ€í•´ ê°ê° ëª¨ë¸ í‰ê°€ ì ìˆ˜ë¥¼ êµ¬í•˜ì‹œì˜¤.

---

### ğŸ’» ì…€ 18 - ì½”ë“œ

```python
reg.score(X_train, y_train) # í›ˆë ¨ ì„¸íŠ¸ í‰ê°€ ì ìˆ˜
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
0.8707088403321211
```

---

### ğŸ’» ì…€ 19 - ì½”ë“œ

```python
reg.score(X_test, y_test) # í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ í‰ê°€ ì ìˆ˜
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
0.8634953212566615
```

---

### ğŸ“ ì…€ 20 - ë§ˆí¬ë‹¤ìš´

## 7) ê²°í˜¼ì‹ ì°¸ì„ ì¸ì›ì´ 300ëª…ì¼ ë•Œ ì˜ˆìƒë˜ëŠ” ì‹ìˆ˜ ì¸ì›ì„ êµ¬í•˜ì‹œì˜¤.

---

### ğŸ’» ì…€ 21 - ì½”ë“œ

```python
total = 300 # ê²°í˜¼ì‹ ì°¸ì„ ì¸ì›
y_pred = reg.predict([[total]])

print(f'ê²°í˜¼ì‹ ì°¸ì„ ì¸ì› {total} ëª…ì— ëŒ€í•œ ì˜ˆìƒ ì‹ìˆ˜ ì¸ì›ì€ {np.around(y_pred[0]).astype(int)} ëª…ì…ë‹ˆë‹¤.')
```

**ğŸ“¤ ì‹¤í–‰ ê²°ê³¼:**

```
ê²°í˜¼ì‹ ì°¸ì„ ì¸ì› 300 ëª…ì— ëŒ€í•œ ì˜ˆìƒ ì‹ìˆ˜ ì¸ì›ì€ 177 ëª…ì…ë‹ˆë‹¤.
```

---


---

## ğŸ“Š ë¶„ì„ ìš”ì•½

- **ì´ ë…¸íŠ¸ë¶ íŒŒì¼**: 6ê°œ
- **ì´ ì…€ ê°œìˆ˜**: 172ê°œ
- **ì½”ë“œ ì…€**: 119ê°œ
- **ë§ˆí¬ë‹¤ìš´ ì…€**: 53ê°œ

## ğŸ”— ìœ ìš©í•œ ë§í¬

- [Jupyter Notebook ê³µì‹ ë¬¸ì„œ](https://jupyter-notebook.readthedocs.io/)
- [Python ê³µì‹ ë¬¸ì„œ](https://docs.python.org/)
- [Notion ë§ˆí¬ë‹¤ìš´ ê°€ì´ë“œ](https://www.notion.so/help/writing-and-editing-basics)

---

âœ¨ **ìë™ ìƒì„±ë¨** - Jupyter to Notion ë³€í™˜ê¸° v1.0
